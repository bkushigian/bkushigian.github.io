---
layout: post
title:  "My Code is Too Good"
date:   2018-08-29 12:00:00 -0400
comments: true
categories: software-dev
group: software-dev
---

This week (just moments ago, in fact) I was once again confronted by my
substantial shortcomings and near-crippling stupidity.


This particular instance of stupidity caused the following baffling behavior:
given my test suite T for [Medusa][medusa], all but a single set of tests, call
it S, passed perfectly, but all the tests in S were failing.

![failure!!]({{ "/assets/img/Failure.png" | absolute_url }})

This is even more interesting since each test could fail in precisely one way:
either the constraints were too strict, or the constraints were too lax, and
all constraints were generated by the same system via the same processes.

Given that, of the 126 test cases, erring towards laxness would be undetectable
in 121 tests and erring towards strictness would be undetectable in the
remaining 5 cases, the probability that my bug would on all instances produce
the (in)correct strict/lax value was very low (with the conservative prior that
there was is a 75% chance of an error in each test (of a system that passes all
other tests, mind you, some of which are rather comprehensive), the probability
is about 1.02e-16).

I'd clearly pissed off some god or other.

Several sacrificial chickens later, after having picked through pages and pages
of generated Z3 constraints trying to find an error, I was miffed at how
correct all my code was. As a side note, it's always trouble when my high code
quality is the thing that's pissing me off. Luckily, I usually resolve this by
finding a truly tremendous blunder; a screwup so spectacular, a gaff so gauche,
that any of that troublesome pride that I may have secretly been accruing is
immediately refuted, and I am forced to consider, once again, a career in
underwater basket weaving, sign spinning, or perhaps as a [lifeguard at olympic
swimming events][olympic-life-guard] (it's pretty niche work, tbh)

It finally occurred to me that a simpler explanation must be at play. After
some more searching I found the culprit: staring at me between the spray of
feathers was a config file (that I had written, of course) on which our
sequence of tests was based. And in this config file was a sequence of bools
determining the expected laxity/strict(ity?) values to be associated with each
of my 126 tests---bools which, it just so happens, were the negative of what
they should have been.

![success!!]({{ "/assets/img/Success.png" | absolute_url }})

[olympic-life-guard]:https://www.nytimes.com/2016/08/05/sports/olympics/olympic-swimming-pool-lifeguards.html
[medusa]:https://drive.google.com/open?id=1gkvAYhlJkKX8neq7eoU17iaFhP0XvgyD
